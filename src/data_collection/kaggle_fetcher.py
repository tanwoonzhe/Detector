"""
Kaggle æ•°æ®è·å–å™¨
================================
è·å–Kaggleä¸Šçš„BTCå†å²æ•°æ®é›†

æ”¯æŒçš„æ•°æ®é›†:
- mczielinski/bitcoin-historical-data (2012-2021, åˆ†é’Ÿçº§)
- sudalairajkumar/cryptocurrencypricehistory (å¤šå¸ç§æ—¥çº§)

ä½¿ç”¨æ–¹æ³•:
1. åœ¨ https://www.kaggle.com/account åˆ›å»ºAPI Token
2. ä¸‹è½½ kaggle.json æ”¾åˆ° ~/.kaggle/ ç›®å½• (Linux/Mac) æˆ– C:/Users/<user>/.kaggle/ (Windows)
3. æˆ–è€…è®¾ç½®ç¯å¢ƒå˜é‡ KAGGLE_USERNAME å’Œ KAGGLE_KEY
"""

import logging
from pathlib import Path
from typing import Optional, List
import pandas as pd
import os

logger = logging.getLogger(__name__)

# Kaggleæ•°æ®é›†é…ç½®
KAGGLE_DATASETS = {
    "bitcoin_bitstamp": {
        "dataset": "mczielinski/bitcoin-historical-data",
        "file_pattern": "bitstamp*.csv",
        "description": "Bitstamp BTC/USD åˆ†é’Ÿçº§æ•°æ® 2012-2021"
    },
    "crypto_prices": {
        "dataset": "sudalairajkumar/cryptocurrencypricehistory",
        "file_pattern": "coin_Bitcoin.csv",
        "description": "BTCæ—¥çº§æ•°æ®"
    }
}


class KaggleFetcher:
    """
    Kaggle æ•°æ®è·å–å™¨
    
    éœ€è¦å…ˆé…ç½®Kaggle APIå‡­è¯
    """
    
    def __init__(self, cache_dir: Optional[Path] = None):
        """
        åˆå§‹åŒ–
        
        Args:
            cache_dir: ç¼“å­˜ç›®å½•ï¼Œé»˜è®¤ä¸º data/raw/kaggle/
        """
        if cache_dir is None:
            cache_dir = Path(__file__).parent.parent.parent / "data" / "raw" / "kaggle"
        
        self.cache_dir = cache_dir
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self._api = None
    
    def _get_api(self):
        """è·å–Kaggle APIå®ä¾‹"""
        if self._api is not None:
            return self._api
        
        try:
            from kaggle.api.kaggle_api_extended import KaggleApi  # type: ignore
            self._api = KaggleApi()
            self._api.authenticate()
            logger.info("âœ… Kaggle API è®¤è¯æˆåŠŸ")
            return self._api
        except ImportError:
            logger.error("âŒ è¯·å…ˆå®‰è£…kaggleåŒ…: pip install kaggle")
            return None
        except Exception as e:
            logger.error(f"âŒ Kaggle API è®¤è¯å¤±è´¥: {e}")
            logger.info("è¯·é…ç½® ~/.kaggle/kaggle.json æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ KAGGLE_USERNAME/KAGGLE_KEY")
            return None
    
    def download_dataset(self, dataset_key: str = "bitcoin_bitstamp") -> Optional[Path]:
        """
        ä¸‹è½½Kaggleæ•°æ®é›†
        
        Args:
            dataset_key: æ•°æ®é›†é”®å
            
        Returns:
            ä¸‹è½½çš„ç›®å½•è·¯å¾„
        """
        if dataset_key not in KAGGLE_DATASETS:
            logger.error(f"æœªçŸ¥æ•°æ®é›†: {dataset_key}")
            logger.info(f"å¯ç”¨æ•°æ®é›†: {list(KAGGLE_DATASETS.keys())}")
            return None
        
        config = KAGGLE_DATASETS[dataset_key]
        dataset_path = self.cache_dir / dataset_key
        
        # æ£€æŸ¥æ˜¯å¦å·²ä¸‹è½½
        if dataset_path.exists() and any(dataset_path.iterdir()):
            logger.info(f"ğŸ“ ä½¿ç”¨ç¼“å­˜æ•°æ®: {dataset_path}")
            return dataset_path
        
        api = self._get_api()
        if api is None:
            return None
        
        try:
            dataset_path.mkdir(parents=True, exist_ok=True)
            
            logger.info(f"ğŸ“¥ ä¸‹è½½Kaggleæ•°æ®é›†: {config['dataset']}")
            logger.info(f"   {config['description']}")
            
            api.dataset_download_files(
                config["dataset"],
                path=str(dataset_path),
                unzip=True
            )
            
            logger.info(f"âœ… ä¸‹è½½å®Œæˆ: {dataset_path}")
            return dataset_path
            
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    def load_bitstamp_data(
        self,
        resample_to: str = "1h",
        start_date: Optional[str] = None,
        end_date: Optional[str] = None
    ) -> pd.DataFrame:
        """
        åŠ è½½Bitstamp BTCåˆ†é’Ÿçº§å†å²æ•°æ®
        
        Args:
            resample_to: é‡é‡‡æ ·é¢‘ç‡ ("1min", "5min", "15min", "30min", "1h", "4h", "1d")
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            
        Returns:
            DataFrame with OHLCV data
        """
        dataset_path = self.download_dataset("bitcoin_bitstamp")
        
        if dataset_path is None:
            # å°è¯•ä»æœ¬åœ°ç¼“å­˜åŠ è½½
            return self._try_load_local()
        
        # æŸ¥æ‰¾CSVæ–‡ä»¶
        csv_files = list(dataset_path.glob("*.csv"))
        if not csv_files:
            logger.error("æœªæ‰¾åˆ°CSVæ–‡ä»¶")
            return pd.DataFrame()
        
        # é€‰æ‹©æœ€å¤§çš„æ–‡ä»¶ï¼ˆé€šå¸¸æ˜¯å®Œæ•´æ•°æ®ï¼‰
        csv_file = max(csv_files, key=lambda f: f.stat().st_size)
        logger.info(f"ğŸ“Š åŠ è½½æ•°æ®æ–‡ä»¶: {csv_file.name}")
        
        try:
            # è¯»å–CSV
            df = pd.read_csv(csv_file)
            
            # å¤„ç†æ—¶é—´æˆ³
            if "Timestamp" in df.columns:
                df["timestamp"] = pd.to_datetime(df["Timestamp"], unit='s')
            elif "timestamp" in df.columns:
                df["timestamp"] = pd.to_datetime(df["timestamp"], unit='s')
            else:
                logger.error("æœªæ‰¾åˆ°æ—¶é—´æˆ³åˆ—")
                return pd.DataFrame()
            
            df.set_index("timestamp", inplace=True)
            
            # æ ‡å‡†åŒ–åˆ—å
            column_mapping = {
                "Open": "open",
                "High": "high",
                "Low": "low",
                "Close": "close",
                "Volume_(BTC)": "volume",
                "Volume_(Currency)": "volume_usd",
                "Weighted_Price": "weighted_price"
            }
            df.rename(columns=column_mapping, inplace=True)
            
            # åªä¿ç•™OHLCV
            ohlcv_cols = ["open", "high", "low", "close", "volume"]
            available_cols = [c for c in ohlcv_cols if c in df.columns]
            df = df[available_cols].copy()
            
            # åˆ é™¤NaNå’Œ0å€¼
            df.replace(0, pd.NA, inplace=True)
            df.dropna(inplace=True)
            
            # æ—¥æœŸè¿‡æ»¤
            if start_date:
                df = df[df.index >= start_date]
            if end_date:
                df = df[df.index <= end_date]
            
            # é‡é‡‡æ ·
            if resample_to != "1min":
                logger.info(f"ğŸ“Š é‡é‡‡æ ·åˆ° {resample_to}...")
                df = df.resample(resample_to).agg({
                    "open": "first",
                    "high": "max",
                    "low": "min",
                    "close": "last",
                    "volume": "sum"
                }).dropna()
            
            logger.info(f"âœ… Kaggleæ•°æ®åŠ è½½å®Œæˆ: {len(df)} æ¡è®°å½•")
            logger.info(f"   æ—¶é—´èŒƒå›´: {df.index.min()} ~ {df.index.max()}")
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return pd.DataFrame()
    
    def _try_load_local(self) -> pd.DataFrame:
        """å°è¯•ä»æœ¬åœ°ç¼“å­˜åŠ è½½"""
        for key in KAGGLE_DATASETS:
            path = self.cache_dir / key
            if path.exists():
                csv_files = list(path.glob("*.csv"))
                if csv_files:
                    logger.info(f"ğŸ“ ä»æœ¬åœ°ç¼“å­˜åŠ è½½: {csv_files[0]}")
                    try:
                        return pd.read_csv(csv_files[0])
                    except Exception:
                        pass
        return pd.DataFrame()
    
    def get_available_datasets(self) -> List[str]:
        """è·å–å¯ç”¨æ•°æ®é›†åˆ—è¡¨"""
        return list(KAGGLE_DATASETS.keys())


def load_kaggle_btc(
    resample_to: str = "1h",
    start_date: Optional[str] = None,
    end_date: Optional[str] = None
) -> pd.DataFrame:
    """
    ä¾¿æ·å‡½æ•°ï¼šåŠ è½½Kaggle BTCæ•°æ®
    
    Args:
        resample_to: é‡é‡‡æ ·é¢‘ç‡
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        
    Returns:
        DataFrame with OHLCV data
    """
    fetcher = KaggleFetcher()
    return fetcher.load_bitstamp_data(
        resample_to=resample_to,
        start_date=start_date,
        end_date=end_date
    )
