"""
FRED (Federal Reserve Economic Data) å®è§‚æ•°æ®è·å–å™¨
================================
ä»ç¾è”å‚¨ç»æµæ•°æ®åº“è·å–å®è§‚ç»æµæŒ‡æ ‡

æ•°æ®æº: https://fred.stlouisfed.org/
å…è´¹API: éœ€è¦æ³¨å†Œè·å–API Key

æ”¯æŒæŒ‡æ ‡:
- åˆ©ç‡: è”é‚¦åŸºé‡‘åˆ©ç‡, å›½å€ºæ”¶ç›Šç‡
- é€šèƒ€: CPI, PCE
- è´§å¸: M2ä¾›åº”é‡
- å¸‚åœº: VIX (é€šè¿‡FREDé•œåƒ)
- å°±ä¸š: å¤±ä¸šç‡
"""

import asyncio
import aiohttp
import logging
from datetime import datetime, timedelta
from typing import Optional, Dict, List, Any
import pandas as pd

logger = logging.getLogger(__name__)

# FRED API åŸºç¡€URL
FRED_BASE_URL = "https://api.stlouisfed.org/fred"

# å¸¸ç”¨å®è§‚æŒ‡æ ‡ç³»åˆ—
MACRO_SERIES = {
    # åˆ©ç‡
    "DFF": "è”é‚¦åŸºé‡‘æœ‰æ•ˆåˆ©ç‡",
    "DGS10": "10å¹´æœŸå›½å€ºæ”¶ç›Šç‡",
    "DGS2": "2å¹´æœŸå›½å€ºæ”¶ç›Šç‡",
    "DGS30": "30å¹´æœŸå›½å€ºæ”¶ç›Šç‡",
    "T10Y2Y": "10å¹´-2å¹´æœŸé™åˆ©å·®",
    "T10Y3M": "10å¹´-3æœˆæœŸé™åˆ©å·®",
    
    # é€šèƒ€
    "CPIAUCSL": "CPI-æ‰€æœ‰åŸå¸‚æ¶ˆè´¹è€…",
    "CPILFESL": "æ ¸å¿ƒCPI (ä¸å«é£Ÿå“èƒ½æº)",
    "PCEPI": "PCEä»·æ ¼æŒ‡æ•°",
    "PCEPILFE": "æ ¸å¿ƒPCE (ä¸å«é£Ÿå“èƒ½æº)",
    
    # è´§å¸ä¾›åº”
    "M2SL": "M2è´§å¸ä¾›åº”é‡",
    "M1SL": "M1è´§å¸ä¾›åº”é‡",
    
    # å¸‚åœºæŒ‡æ ‡
    "VIXCLS": "VIXææ…ŒæŒ‡æ•°",
    "SP500": "æ ‡æ™®500æŒ‡æ•°",
    "NASDAQCOM": "çº³æ–¯è¾¾å…‹ç»¼åˆæŒ‡æ•°",
    "DTWEXBGS": "ç¾å…ƒæŒ‡æ•° (å¹¿ä¹‰)",
    
    # å°±ä¸š
    "UNRATE": "å¤±ä¸šç‡",
    "PAYEMS": "éå†œå°±ä¸šäººæ•°",
    "ICSA": "é¦–æ¬¡ç”³è¯·å¤±ä¸šæ•‘æµäººæ•°",
    
    # ç»æµæ´»åŠ¨
    "INDPRO": "å·¥ä¸šç”Ÿäº§æŒ‡æ•°",
    "RSAFS": "é›¶å”®é”€å”®",
    "DGORDER": "è€ç”¨å“è®¢å•",
    
    # æˆ¿åœ°äº§
    "CSUSHPISA": "Case-Shilleræˆ¿ä»·æŒ‡æ•°",
    
    # å¤§å®—å•†å“
    "DCOILWTICO": "WTIåŸæ²¹ä»·æ ¼",
    "GOLDAMGBD228NLBM": "é»„é‡‘ä»·æ ¼(ä¼¦æ•¦)",
}

# ä¸BTCç›¸å…³æ€§è¾ƒé«˜çš„æ ¸å¿ƒæŒ‡æ ‡
BTC_RELATED_SERIES = [
    "DFF",       # è”é‚¦åŸºé‡‘åˆ©ç‡ - è´§å¸æ”¿ç­–
    "DGS10",     # 10å¹´æœŸå›½å€º - æ— é£é™©åˆ©ç‡
    "DGS2",      # 2å¹´æœŸå›½å€º
    "T10Y2Y",    # æœŸé™åˆ©å·® - ç»æµé¢„æœŸ
    "CPIAUCSL",  # CPI - é€šèƒ€
    "M2SL",      # M2 - æµåŠ¨æ€§
    "VIXCLS",    # VIX - é£é™©æƒ…ç»ª
    "DTWEXBGS",  # ç¾å…ƒæŒ‡æ•°
    "DCOILWTICO", # åŸæ²¹ - é€šèƒ€é¢„æœŸ
]


class FREDFetcher:
    """
    FRED å®è§‚æ•°æ®è·å–å™¨
    
    éœ€è¦FRED API Keyï¼Œå¯åœ¨ä»¥ä¸‹ç½‘å€å…è´¹æ³¨å†Œ:
    https://fred.stlouisfed.org/docs/api/api_key.html
    """
    
    def __init__(self, api_key: str = ""):
        """
        åˆå§‹åŒ–
        
        Args:
            api_key: FRED API Key
        """
        self.api_key = api_key
        self.base_url = FRED_BASE_URL
        self._session: Optional[aiohttp.ClientSession] = None
    
    async def _get_session(self) -> aiohttp.ClientSession:
        """è·å–HTTPä¼šè¯"""
        if self._session is None or self._session.closed:
            self._session = aiohttp.ClientSession()
        return self._session
    
    async def close(self):
        """å…³é—­ä¼šè¯"""
        if self._session and not self._session.closed:
            await self._session.close()
    
    async def _request(self, endpoint: str, params: Optional[Dict] = None) -> Dict:
        """å‘é€APIè¯·æ±‚"""
        if not self.api_key:
            raise ValueError("FRED API Keyæœªè®¾ç½®ï¼Œè¯·åœ¨.envä¸­è®¾ç½®FRED_API_KEY")
        
        session = await self._get_session()
        url = f"{self.base_url}/{endpoint}"
        
        if params is None:
            params = {}
        params["api_key"] = self.api_key
        params["file_type"] = "json"
        
        try:
            async with session.get(url, params=params) as response:
                if response.status == 200:
                    return await response.json()
                else:
                    text = await response.text()
                    logger.error(f"FRED APIé”™è¯¯ {response.status}: {text}")
                    return {}
        except Exception as e:
            logger.error(f"FRED APIè¯·æ±‚å¤±è´¥: {e}")
            return {}
    
    async def get_series(
        self,
        series_id: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        frequency: Optional[str] = None
    ) -> pd.DataFrame:
        """
        è·å–å•ä¸ªç»æµæŒ‡æ ‡æ—¶é—´åºåˆ—
        
        Args:
            series_id: FREDç³»åˆ—ID (å¦‚ "DFF", "DGS10")
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            frequency: é¢‘ç‡ (d=æ—¥, w=å‘¨, m=æœˆ, q=å­£, a=å¹´)
            
        Returns:
            DataFrame with date index and value column
        """
        if start_date is None:
            start_date = "2010-01-01"
        if end_date is None:
            end_date = datetime.now().strftime("%Y-%m-%d")
        
        params = {
            "series_id": series_id,
            "observation_start": start_date,
            "observation_end": end_date,
        }
        
        if frequency:
            params["frequency"] = frequency
        
        logger.info(f"ğŸ“¥ è·å–FREDæ•°æ®: {series_id} ({MACRO_SERIES.get(series_id, '')})")
        
        data = await self._request("series/observations", params)
        
        if not data or "observations" not in data:
            logger.warning(f"FREDè¿”å›ç©ºæ•°æ®: {series_id}")
            return pd.DataFrame()
        
        # è§£ææ•°æ®
        records = []
        for obs in data["observations"]:
            try:
                value = float(obs["value"]) if obs["value"] != "." else None
                records.append({
                    "timestamp": pd.to_datetime(obs["date"]),
                    f"fred_{series_id.lower()}": value
                })
            except (ValueError, KeyError):
                continue
        
        if not records:
            return pd.DataFrame()
        
        df = pd.DataFrame(records)
        df.set_index("timestamp", inplace=True)
        df.sort_index(inplace=True)
        
        # åˆ é™¤NaN
        df.dropna(inplace=True)
        
        logger.info(f"âœ… {series_id}: {len(df)} æ¡è®°å½• ({df.index.min().date()} ~ {df.index.max().date()})")
        
        return df
    
    async def get_multiple_series(
        self,
        series_ids: Optional[List[str]] = None,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None
    ) -> pd.DataFrame:
        """
        è·å–å¤šä¸ªç»æµæŒ‡æ ‡å¹¶åˆå¹¶
        
        Args:
            series_ids: ç³»åˆ—IDåˆ—è¡¨ï¼Œé»˜è®¤ä½¿ç”¨BTCç›¸å…³æŒ‡æ ‡
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            åˆå¹¶åçš„DataFrame
        """
        if series_ids is None:
            series_ids = BTC_RELATED_SERIES
        
        logger.info(f"ğŸ“¥ æ‰¹é‡è·å–FREDæ•°æ®: {len(series_ids)} ä¸ªæŒ‡æ ‡")
        
        # å¹¶è¡Œè·å–æ‰€æœ‰æ•°æ®
        tasks = [
            self.get_series(sid, start_date, end_date)
            for sid in series_ids
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # åˆå¹¶æ•°æ®
        dfs = []
        for sid, result in zip(series_ids, results):
            if isinstance(result, Exception):
                logger.warning(f"è·å– {sid} å¤±è´¥: {result}")
            elif isinstance(result, pd.DataFrame) and not result.empty:
                dfs.append(result)
        
        if not dfs:
            logger.warning("æ²¡æœ‰è·å–åˆ°ä»»ä½•FREDæ•°æ®")
            return pd.DataFrame()
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        df_merged = dfs[0]
        for df in dfs[1:]:
            df_merged = df_merged.join(df, how="outer")
        
        df_merged.sort_index(inplace=True)
        
        # å‰å‘å¡«å……ï¼ˆå®è§‚æ•°æ®æ›´æ–°è¾ƒæ…¢ï¼‰
        df_merged.ffill(inplace=True)
        
        logger.info(f"âœ… FREDæ•°æ®åˆå¹¶å®Œæˆ: {len(df_merged)} æ¡è®°å½•, {len(df_merged.columns)} åˆ—")
        
        return df_merged
    
    async def get_btc_related_macro(
        self,
        start_date: str = "2017-01-01",
        end_date: Optional[str] = None
    ) -> pd.DataFrame:
        """
        è·å–ä¸BTCç›¸å…³çš„å®è§‚æŒ‡æ ‡
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            DataFrame with macro indicators
        """
        return await self.get_multiple_series(
            series_ids=BTC_RELATED_SERIES,
            start_date=start_date,
            end_date=end_date
        )
    
    def get_available_series(self) -> Dict[str, str]:
        """è·å–å¯ç”¨çš„æŒ‡æ ‡åˆ—è¡¨"""
        return MACRO_SERIES.copy()


async def fetch_fred_macro(
    api_key: str,
    start_date: str = "2017-01-01"
) -> pd.DataFrame:
    """
    ä¾¿æ·å‡½æ•°ï¼šè·å–FREDå®è§‚æ•°æ®
    
    Args:
        api_key: FRED API Key
        start_date: å¼€å§‹æ—¥æœŸ
        
    Returns:
        DataFrame with macro indicators
    """
    fetcher = FREDFetcher(api_key=api_key)
    
    try:
        df = await fetcher.get_btc_related_macro(start_date=start_date)
        return df
    finally:
        await fetcher.close()
