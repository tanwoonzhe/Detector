"""
æ¨¡å‹è®­ç»ƒè„šæœ¬
================================
è®­ç»ƒBTCè¶‹åŠ¿é¢„æµ‹æ¨¡å‹

ä½¿ç”¨æ–¹æ³•:
    python train.py --model gru --epochs 100
    python train.py --model all --epochs 50
"""

import argparse
import asyncio
import logging
import sys
from pathlib import Path
from datetime import datetime

import numpy as np
import pandas as pd

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from config import ModelConfig, TradingConfig, FeatureConfig
from src.data_collection import CacheManager
from src.data_collection.coingecko_fetcher import CoinGeckoFetcher
from src.sentiment import SentimentAggregator
from src.features import FeatureEngineer
from src.validation import WalkForwardValidator, TimeSeriesMetrics
from src.models import (
    GRUPredictor, 
    BiLSTMPredictor, 
    CNNLSTMPredictor,
    LightGBMPredictor,
    ModelEnsemble
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def fetch_data(use_hf: bool = False, merge_recent: bool = False):
    """è·å–è®­ç»ƒæ•°æ®"""
    logger.info("è·å–å†å²æ•°æ®...")
    
    df = None
    
    # é€‰é¡¹1: ä½¿ç”¨ HuggingFace å†å²æ•°æ®
    if use_hf:
        logger.info("ğŸ“¥ åŠ è½½ HuggingFace å†å²æ•°æ®é›†...")
        try:
            from src.data_collection.hf_loader_fixed import load_hf_btc_data
            df = load_hf_btc_data()
            
            if not df.empty:
                logger.info(f"âœ… HFæ•°æ®åŠ è½½æˆåŠŸ: {len(df)} æ¡è®°å½•")
                logger.info(f"   æ—¶é—´èŒƒå›´: {df.index.min()} ~ {df.index.max()}")
                
                # å¦‚æœéœ€è¦åˆå¹¶æœ€æ–°æ•°æ®
                if merge_recent:
                    logger.info("ğŸ“Š åˆå¹¶æœ€æ–° CoinGecko æ•°æ®...")
                    fetcher = CoinGeckoFetcher()
                    recent_data = await fetcher.get_hourly_ohlcv(
                        symbol="bitcoin",
                        vs_currency="usd",
                        days=7  # è·å–æœ€è¿‘7å¤©æ•°æ®
                    )
                    await fetcher.close()
                    
                    df_recent = recent_data.to_dataframe()
                    
                    # åªä¿ç•™ HF æ•°æ®ä¹‹åçš„éƒ¨åˆ†
                    df_recent = df_recent[df_recent.index > df.index.max()]
                    
                    if not df_recent.empty:
                        logger.info(f"   æ–°å¢ {len(df_recent)} æ¡æœ€æ–°æ•°æ®")
                        df = pd.concat([df, df_recent]).sort_index()
                    
            else:
                logger.warning("âš ï¸ HFæ•°æ®åŠ è½½å¤±è´¥ï¼Œå›é€€åˆ° CoinGecko")
                df = None
                
        except Exception as e:
            logger.error(f"âŒ HFæ•°æ®åŠ è½½å¼‚å¸¸: {e}")
            df = None
    
    # å¦‚æœæ²¡æœ‰ä½¿ç”¨HFæˆ–HFåŠ è½½å¤±è´¥ï¼Œä½¿ç”¨ CoinGecko
    if df is None or df.empty:
        logger.info("ğŸ“Š ä½¿ç”¨ CoinGecko è·å–90å¤©å°æ—¶æ•°æ®...")
        fetcher = CoinGeckoFetcher()
        
        market_data = await fetcher.get_hourly_ohlcv(
            symbol="bitcoin",
            vs_currency="usd",
            days=90  # 90å¤©æ•°æ®ï¼Œçº¦2160æ¡
        )
        
        # è½¬æ¢ä¸ºDataFrame
        df = market_data.to_dataframe()
        logger.info(f"åŸå§‹æ•°æ®: {len(df)} æ¡ (èŒƒå›´: {df.index.min()} ~ {df.index.max()})")
        
        await fetcher.close()
    
    # ç¡®ä¿æ—¶åŒºä¸€è‡´
    if hasattr(df.index, 'tz'):
        if df.index.tz is None:  # type: ignore
            df.index = df.index.tz_localize('UTC')  # type: ignore
        else:
            df.index = df.index.tz_convert('UTC')  # type: ignore
    
    return df


def prepare_data(df: pd.DataFrame):
    """å‡†å¤‡è®­ç»ƒæ•°æ®"""
    logger.info(f"ç‰¹å¾å·¥ç¨‹å¼€å§‹... åˆå§‹æ•°æ®: {len(df)} è¡Œ")
    
    engineer = FeatureEngineer()
    
    # åˆ›å»ºç‰¹å¾
    df_features = engineer.create_features(df)
    logger.info(f"ç‰¹å¾åˆ›å»ºå: {len(df_features)} è¡Œ")
    
    if len(df_features) < 50:
        logger.error(f"ç‰¹å¾å·¥ç¨‹åæ•°æ®ä¸è¶³: {len(df_features)} è¡Œ < 50 è¡Œæœ€å°è¦æ±‚")
        raise ValueError(
            f"ç‰¹å¾å·¥ç¨‹åä»…å‰© {len(df_features)} è¡Œæ•°æ®ï¼Œä¸è¶³ä»¥è®­ç»ƒã€‚"
            f"å»ºè®®ï¼š1) ä½¿ç”¨æ›´å¤šå¤©æ•°çš„æ•°æ® 2) å‡å°ç‰¹å¾çª—å£å¤§å°ï¼ˆå½“å‰SEQUENCE_LENGTH={ModelConfig.SEQUENCE_LENGTH}ï¼‰"
        )
    
    # åˆ›å»ºæ ‡ç­¾
    df_features = engineer.create_labels(df_features)
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    X, y, feature_names = engineer.prepare_training_data(
        df_features, 
        target_window=1,  # 1å°æ—¶é¢„æµ‹
        for_classification=True
    )
    
    # åˆ›å»ºåºåˆ—
    X_seq, y_seq = engineer.create_sequences(X, y)
    
    logger.info(f"ç‰¹å¾ç»´åº¦: {X_seq.shape}")
    logger.info(f"ç±»åˆ«åˆ†å¸ƒ: {np.bincount(y_seq.astype(int))}")
    
    return X_seq, y_seq, feature_names


def train_gru(X_train, y_train, X_val, y_val):
    """è®­ç»ƒGRUæ¨¡å‹"""
    logger.info("è®­ç»ƒGRUæ¨¡å‹...")
    
    model = GRUPredictor(
        hidden_size=ModelConfig.GRU_HIDDEN_SIZE,
        num_layers=ModelConfig.GRU_NUM_LAYERS,
        dropout=ModelConfig.DROPOUT,
        epochs=ModelConfig.EPOCHS,
        batch_size=ModelConfig.BATCH_SIZE,
        learning_rate=ModelConfig.LEARNING_RATE
    )
    
    model.build(input_shape=(X_train.shape[1], X_train.shape[2]), n_classes=3)
    history = model.train(X_train, y_train, X_val, y_val)
    
    return model, history


def train_bilstm(X_train, y_train, X_val, y_val):
    """è®­ç»ƒBiLSTMæ¨¡å‹"""
    logger.info("è®­ç»ƒBiLSTMæ¨¡å‹...")
    
    model = BiLSTMPredictor(
        hidden_size=ModelConfig.LSTM_HIDDEN_SIZE,
        num_layers=ModelConfig.LSTM_NUM_LAYERS,
        dropout=ModelConfig.DROPOUT,
        epochs=ModelConfig.EPOCHS,
        batch_size=ModelConfig.BATCH_SIZE
    )
    
    model.build(input_shape=(X_train.shape[1], X_train.shape[2]), n_classes=3)
    history = model.train(X_train, y_train, X_val, y_val)
    
    return model, history


def train_cnn_lstm(X_train, y_train, X_val, y_val):
    """è®­ç»ƒCNN-LSTMæ¨¡å‹"""
    logger.info("è®­ç»ƒCNN-LSTMæ¨¡å‹...")
    
    model = CNNLSTMPredictor(
        cnn_filters=64,
        kernel_sizes=[3, 5, 7],
        lstm_hidden=ModelConfig.LSTM_HIDDEN_SIZE,
        lstm_layers=2,
        dropout=ModelConfig.DROPOUT,
        epochs=ModelConfig.EPOCHS,
        batch_size=ModelConfig.BATCH_SIZE
    )
    
    model.build(input_shape=(X_train.shape[1], X_train.shape[2]), n_classes=3)
    history = model.train(X_train, y_train, X_val, y_val)
    
    return model, history


def train_lightgbm(X_train, y_train, X_val, y_val):
    """è®­ç»ƒLightGBMæ¨¡å‹"""
    logger.info("è®­ç»ƒLightGBMæ¨¡å‹...")
    
    model = LightGBMPredictor(
        n_estimators=500,
        max_depth=6,
        learning_rate=0.05
    )
    
    model.build()
    history = model.train(X_train, y_train, X_val, y_val)
    
    return model, history


def evaluate_model(model, X_test, y_test, name: str):
    """è¯„ä¼°æ¨¡å‹"""
    logger.info(f"è¯„ä¼° {name}...")
    
    y_pred = model.predict(X_test)
    metrics = TimeSeriesMetrics.calculate_metrics(y_test, y_pred)
    
    logger.info(f"  å‡†ç¡®ç‡: {metrics['accuracy']:.4f}")
    logger.info(f"  F1åˆ†æ•°: {metrics['f1_macro']:.4f}")
    
    return metrics


def walk_forward_validation(X, y, model_class, model_kwargs):
    """Walk-ForwardéªŒè¯"""
    logger.info("æ‰§è¡ŒWalk-ForwardéªŒè¯...")
    
    validator = WalkForwardValidator(
        train_size=168 * 4,  # 4å‘¨è®­ç»ƒ
        test_size=168,       # 1å‘¨æµ‹è¯•
        step_size=24,        # æ¯å¤©æ»šåŠ¨
        expanding=True
    )
    
    all_metrics = []
    
    for fold, (train_idx, test_idx) in enumerate(validator.split(X)):
        logger.info(f"  Fold {fold + 1}...")
        
        X_train, X_test = X[train_idx], X[test_idx]
        y_train, y_test = y[train_idx], y[test_idx]
        
        # è®­ç»ƒæ¨¡å‹
        model = model_class(**model_kwargs)
        model.build(input_shape=(X_train.shape[1], X_train.shape[2]), n_classes=3)
        model.train(X_train, y_train)
        
        # è¯„ä¼°
        y_pred = model.predict(X_test)
        metrics = TimeSeriesMetrics.calculate_metrics(y_test, y_pred)
        all_metrics.append(metrics)
        
        if fold >= 4:  # é™åˆ¶foldæ•°é‡
            break
    
    # å¹³å‡æŒ‡æ ‡
    avg_metrics = {
        key: np.mean([m[key] for m in all_metrics])
        for key in all_metrics[0].keys()
    }
    
    logger.info(f"  å¹³å‡å‡†ç¡®ç‡: {avg_metrics['accuracy']:.4f}")
    logger.info(f"  å¹³å‡F1: {avg_metrics['f1_macro']:.4f}")
    
    return avg_metrics


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è®­ç»ƒBTCè¶‹åŠ¿é¢„æµ‹æ¨¡å‹')
    parser.add_argument('--model', type=str, default='gru',
                       choices=['gru', 'bilstm', 'cnn_lstm', 'lightgbm', 'all'],
                       help='è¦è®­ç»ƒçš„æ¨¡å‹')
    parser.add_argument('--epochs', type=int, default=ModelConfig.EPOCHS,
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=ModelConfig.BATCH_SIZE,
                       help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--validate', action='store_true',
                       help='æ˜¯å¦æ‰§è¡ŒWalk-ForwardéªŒè¯')
    parser.add_argument('--use-hf', action='store_true',
                       help='ä½¿ç”¨HuggingFaceå†å²æ•°æ®é›†')
    parser.add_argument('--merge-recent', action='store_true',
                       help='åˆå¹¶æœ€è¿‘çš„CoinGeckoæ•°æ®ï¼ˆä¸--use-hfä¸€èµ·ä½¿ç”¨ï¼‰')
    args = parser.parse_args()
    
    # æ›´æ–°é…ç½®
    ModelConfig.EPOCHS = args.epochs
    ModelConfig.BATCH_SIZE = args.batch_size
    
    logger.info("="*50)
    logger.info("BTCè¶‹åŠ¿é¢„æµ‹æ¨¡å‹è®­ç»ƒ")
    logger.info("="*50)
    
    # è·å–æ•°æ®
    try:
        df = asyncio.run(fetch_data(use_hf=args.use_hf, merge_recent=args.merge_recent))
    except Exception as e:
        logger.error(f"è·å–æ•°æ®å¤±è´¥: {e}")
        logger.info("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤º...")
        
        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        np.random.seed(42)
        dates = pd.date_range(end=datetime.now(), periods=2160, freq='H')
        returns = np.random.randn(2160) * 0.01
        prices = 65000 * np.cumprod(1 + returns)
        
        df = pd.DataFrame({
            'open': prices * (1 - np.random.rand(2160) * 0.005),
            'high': prices * (1 + np.random.rand(2160) * 0.01),
            'low': prices * (1 - np.random.rand(2160) * 0.01),
            'close': prices,
            'volume': np.random.rand(2160) * 1e9
        }, index=dates)
    
    # å‡†å¤‡æ•°æ®
    X_seq, y_seq, feature_names = prepare_data(df)
    
    # åˆ†å‰²è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†
    n = len(X_seq)
    train_end = int(n * 0.7)
    val_end = int(n * 0.85)
    
    X_train = X_seq[:train_end]
    y_train = y_seq[:train_end]
    X_val = X_seq[train_end:val_end]
    y_val = y_seq[train_end:val_end]
    X_test = X_seq[val_end:]
    y_test = y_seq[val_end:]
    
    logger.info(f"è®­ç»ƒé›†: {len(X_train)}, éªŒè¯é›†: {len(X_val)}, æµ‹è¯•é›†: {len(X_test)}")
    
    # ä¿å­˜æ¨¡å‹çš„ç›®å½•
    model_dir = Path(__file__).parent / 'models' / 'saved'
    model_dir.mkdir(parents=True, exist_ok=True)
    
    models = {}
    
    # è®­ç»ƒæ¨¡å‹
    if args.model in ['gru', 'all']:
        model, _ = train_gru(X_train, y_train, X_val, y_val)
        models['gru'] = model
        evaluate_model(model, X_test, y_test, 'GRU')
        model.save(model_dir / 'gru_model.pt')
    
    if args.model in ['bilstm', 'all']:
        model, _ = train_bilstm(X_train, y_train, X_val, y_val)
        models['bilstm'] = model
        evaluate_model(model, X_test, y_test, 'BiLSTM')
        model.save(model_dir / 'bilstm_model.pt')
    
    if args.model in ['cnn_lstm', 'all']:
        model, _ = train_cnn_lstm(X_train, y_train, X_val, y_val)
        models['cnn_lstm'] = model
        evaluate_model(model, X_test, y_test, 'CNN-LSTM')
        model.save(model_dir / 'cnn_lstm_model.pt')
    
    if args.model in ['lightgbm', 'all']:
        model, _ = train_lightgbm(X_train, y_train, X_val, y_val)
        models['lightgbm'] = model
        evaluate_model(model, X_test, y_test, 'LightGBM')
        model.save(model_dir / 'lightgbm_model.pkl')
    
    # é›†æˆæ¨¡å‹
    if args.model == 'all' and len(models) > 1:
        logger.info("åˆ›å»ºé›†æˆæ¨¡å‹...")
        ensemble = ModelEnsemble(
            models=list(models.values()),
            strategy='soft_voting'
        )
        
        # è¯„ä¼°é›†æˆ
        y_pred = ensemble.predict(X_test)
        metrics = TimeSeriesMetrics.calculate_metrics(y_test, y_pred)
        logger.info(f"é›†æˆå‡†ç¡®ç‡: {metrics['accuracy']:.4f}")
        logger.info(f"é›†æˆF1: {metrics['f1_macro']:.4f}")
    
    # Walk-ForwardéªŒè¯
    if args.validate:
        logger.info("\næ‰§è¡ŒWalk-ForwardéªŒè¯...")
        wf_metrics = walk_forward_validation(
            X_seq, y_seq,
            GRUPredictor,
            {'hidden_size': 128, 'num_layers': 2, 'epochs': 50}
        )
    
    logger.info("\n" + "="*50)
    logger.info("è®­ç»ƒå®Œæˆï¼")
    logger.info(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {model_dir}")
    logger.info("="*50)


if __name__ == "__main__":
    main()
