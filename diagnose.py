#!/usr/bin/env python3
"""
å¿«é€Ÿè¯Šæ–­è„šæœ¬
============
æ£€æŸ¥ä¿®å¤æ˜¯å¦æ­£ç¡®åº”ç”¨
"""
import sys
from pathlib import Path

print("=" * 70)
print("ğŸ” è¯Šæ–­æ£€æŸ¥ - ä¿®å¤çŠ¶æ€")
print("=" * 70)

# 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
print("\n1ï¸âƒ£  æ£€æŸ¥å…³é”®æ–‡ä»¶...")
files_to_check = [
    "src/data_collection/hf_loader_fixed.py",
    "src/data_collection/hf_loader.py",
    "src/models/base.py",
    "src/models/gru.py",
    "main.py",
]

for file in files_to_check:
    filepath = Path(file)
    if filepath.exists():
        print(f"  âœ… {file}")
    else:
        print(f"  âŒ {file} ä¸å­˜åœ¨ï¼")

# 2. æ£€æŸ¥å…³é”®ä»£ç æ˜¯å¦å·²æ›´æ–°
print("\n2ï¸âƒ£  æ£€æŸ¥ä»£ç æ˜¯å¦å·²æ›´æ–°...")

checks = [
    {
        "file": "src/data_collection/hf_loader_fixed.py",
        "search": ".agg(agg_dict)",
        "desc": "HF loaderä½¿ç”¨aggæ–¹æ³•"
    },
    {
        "file": "src/data_collection/hf_loader.py",
        "search": ".agg(agg_dict)",
        "desc": "HF loader(æ—§)ä½¿ç”¨aggæ–¹æ³•"
    },
    {
        "file": "src/models/base.py",
        "search": "auto_build",
        "desc": "æ¨¡å‹åŠ è½½æ”¯æŒauto_build"
    },
    {
        "file": "main.py",
        "search": "auto_build=True",
        "desc": "main.pyä½¿ç”¨auto_build"
    }
]

for check in checks:
    filepath = Path(check["file"])
    if not filepath.exists():
        print(f"  âš ï¸  {check['desc']}: æ–‡ä»¶ä¸å­˜åœ¨")
        continue
    
    content = filepath.read_text(encoding='utf-8')
    if check["search"] in content:
        print(f"  âœ… {check['desc']}")
    else:
        print(f"  âŒ {check['desc']} - ä»£ç æœªæ›´æ–°ï¼")

# 3. æ£€æŸ¥ç¼“å­˜æ–‡ä»¶
print("\n3ï¸âƒ£  æ£€æŸ¥ç¼“å­˜æ–‡ä»¶...")
cache_files = [
    "data/raw/hf_btc_hourly.parquet",
    "data/raw/hf_btc_hourly.csv",
]

any_cache = False
for cache_file in cache_files:
    filepath = Path(cache_file)
    if filepath.exists():
        print(f"  âš ï¸  å‘ç°ç¼“å­˜: {cache_file}")
        print(f"      å¤§å°: {filepath.stat().st_size / 1024 / 1024:.2f} MB")
        print(f"      å»ºè®®: åˆ é™¤æ­¤æ–‡ä»¶ä»¥å¼ºåˆ¶é‡æ–°åŠ è½½æ•°æ®")
        any_cache = True

if not any_cache:
    print("  âœ… æ²¡æœ‰å‘ç°æ—§ç¼“å­˜æ–‡ä»¶")

# 4. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
print("\n4ï¸âƒ£  æ£€æŸ¥æ¨¡å‹æ–‡ä»¶...")
model_dirs = [
    "models/saved",
    "data/models",
]

any_model = False
for model_dir in model_dirs:
    dirpath = Path(model_dir)
    if dirpath.exists():
        models = list(dirpath.glob("*.pt")) + list(dirpath.glob("*.pth"))
        if models:
            print(f"  ğŸ“¦ {model_dir}:")
            for model in models:
                size_mb = model.stat().st_size / 1024 / 1024
                print(f"      - {model.name} ({size_mb:.2f} MB)")
                any_model = True

if not any_model:
    print("  â„¹ï¸  æ²¡æœ‰å‘ç°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆéœ€è¦å…ˆè®­ç»ƒï¼‰")

# 5. ç¯å¢ƒæ£€æŸ¥
print("\n5ï¸âƒ£  ç¯å¢ƒä¿¡æ¯...")
print(f"  Python: {sys.version.split()[0]}")
print(f"  å¹³å°: {sys.platform}")

try:
    import pandas as pd
    print(f"  Pandas: {pd.__version__}")
except:
    print("  Pandas: æœªå®‰è£…")

try:
    import torch
    print(f"  PyTorch: {torch.__version__}")
except:
    print("  PyTorch: æœªå®‰è£…æˆ–æ— æ³•åŠ è½½")

# æ€»ç»“
print("\n" + "=" * 70)
print("ğŸ“‹ è¯Šæ–­æ€»ç»“")
print("=" * 70)

print("""
å¦‚æœçœ‹åˆ° âŒ æ ‡è®°ï¼š
  â†’ ä»£ç å¯èƒ½æœªæ­£ç¡®æ›´æ–°ï¼Œè¯·é‡æ–°æ‹‰å–ä»£ç 

å¦‚æœçœ‹åˆ° âš ï¸  ç¼“å­˜è­¦å‘Šï¼š
  â†’ åˆ é™¤ç¼“å­˜æ–‡ä»¶: rm data/raw/hf_btc_hourly.*

å¦‚æœæ¨¡å‹åŠ è½½ä»ç„¶æŠ¥é”™ï¼š
  â†’ åˆ é™¤æ—§æ¨¡å‹å¹¶é‡æ–°è®­ç»ƒ: rm models/saved/*.pth && python train.py

å¦‚æœæ•°æ®åŠ è½½ä»ç„¶æŠ¥é”™ï¼š
  â†’ ç¡®ä¿ä½¿ç”¨æœ€æ–°ä»£ç å¹¶åˆ é™¤æ‰€æœ‰ç¼“å­˜
  â†’ æ£€æŸ¥ traceback ä¸­çš„æ–‡ä»¶è·¯å¾„æ˜¯å¦æŒ‡å‘æ­£ç¡®çš„æ–‡ä»¶
""")

print("=" * 70)
